---
layout: post
title:  "聊聊正则化中的 L0，L1，L2 范数"
date:   2018-12-13
categories: [知识]
tags: [Deep Learning]
---


## L0范数
L0范数是指向量中非0的元素的个数。因此，如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0。

## L1范数
L1范数是指向量中各个元素绝对值之和，也叫“稀疏正则算子”（Lasso regularization）。

既然L0可以实现稀疏，为什么不用L0，而要用L1呢？
* 因为L0范数很难优化求解（NP难问题）
* L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。

另外，参数稀疏的好处有
1. 特征选择
2. 可解释性

## L2范数
L2范数是指向量各元素的平方和然后求平方根。

我们让L2范数的规则项 $\|\|W\|\|^2$ 最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。

为什么越小的参数说明模型越简单？限制了参数很小，实际上就限制了多项式某些分量的影响很小。

因此，L2范数的好处有：
* 可以防止过拟合，提升模型的泛化能力。
* 可以让优化求解变得稳定快速

## 总结
L1会趋向于产生少量的特征，而其他的特征都是0；而L2会选择更多的特征，这些特征都会接近于0。

> 参考资料：[机器学习中的范数规则化之（一）L0、L1与L2范数](https://blog.csdn.net/zouxy09/article/details/24971995)


